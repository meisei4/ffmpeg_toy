import sys

from utils.ffmpeg_utils import run_command


def sync_video(args) -> None:
    """
    Synchronize video by stretching a portion until a musical cue and then splicing in an accelerated segment.

    The output video (args.output) will have a silent audio track injected,
    ensuring the final file has both video and audio.
    """
    try:
        audio_cue: float = float(args.audio_cue)
        cue_end: float = float(args.cue_end)
        seg_start: float = float(args.segment_start)
        seg_end: float = float(args.segment_end)
    except ValueError:
        print("audio-cue, cue-end, segment-start, and segment-end must be numeric.")
        sys.exit(1)

    if seg_start <= 0 or seg_end <= seg_start:
        print("Invalid segment times: Ensure segment_start > 0 and segment_end > segment_start.")
        sys.exit(1)
    if cue_end <= audio_cue:
        print("Invalid cue times: cue-end must be greater than audio-cue.")
        sys.exit(1)

    # Compute time stretch and speed factors.
    time_factor: float = audio_cue / seg_start
    print(f"Calculated time stretch factor: {time_factor:.2f} (to stretch {seg_start}s to {audio_cue}s)")

    splice_original_duration: float = seg_end - seg_start
    desired_splice_duration: float = cue_end - audio_cue
    speed_factor: float = splice_original_duration / desired_splice_duration
    print(
        f"Calculated speed factor: {speed_factor:.2f} (to compress {splice_original_duration}s to {desired_splice_duration}s)")

    # Build filter_complex without any glitch effect.
    # - Segment 1: from 0 to seg_start, stretched by multiplying PTS.
    # - Segment 2: from seg_start to seg_end, sped up by dividing the PTS.
    # Then the two segments are concatenated.
    filter_complex: str = (
        f"[1:v]trim=start=0:end={seg_start},setpts=PTS*{time_factor}[seg1]; "
        f"[1:v]trim=start={seg_start}:end={seg_end},setpts=(PTS-STARTPTS)/{speed_factor}[seg2]; "
        f"[seg1][seg2]concat=n=2:v=1:a=0[outv]"
    )
    print("Constructed filter_complex:")
    print(filter_complex)

    # Build the command using two inputs:
    # - Input 0: a silent audio stream generated by anullsrc.
    # - Input 1: the actual video file.
    # The final output maps the video from the filter output and the silent audio from input 0.
    cmd = [
        "ffmpeg", "-y",
        "-f", "lavfi", "-i", "anullsrc=cl=stereo:r=48000",  # Input 0: Silent audio
        "-i", args.input,  # Input 1: Video file
        "-filter_complex", filter_complex,
        "-map", "[outv]",
        "-map", "0:a",
        "-shortest",
        "-c:v", "libx265",
        "-c:a", "aac",
        args.output
    ]
    from utils.ffmpeg_utils import run_command
    run_command(cmd)
    print(f"Synchronized video with silent audio saved to {args.output}")
